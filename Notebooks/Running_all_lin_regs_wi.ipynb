{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "from datetime import datetime as DT\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "from theano import shared\n",
    "from pymc_models import PyMCModel\n",
    "from pymc_models import hs_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../PickleJar/DataSets/AphiTrainTestSplitDataSets.pkl', 'rb') as fb:\n",
    "    datadict = pickle.load(fb)\n",
    "X_s_train = datadict['x_train_s']\n",
    "y_train = datadict['y_train']\n",
    "X_s_test = datadict['x_test_s']\n",
    "y_test = datadict['y_test']\n",
    "X_s_train_w_int = datadict['x_train_wi_s']\n",
    "X_s_test_w_int = datadict['x_test_wi_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-11 10:36:43.101 | INFO     | __main__:<module>:11 - processing aphi411\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, bias, w, lambda_m, sd_bias, tau]\n",
      "Sampling 4 chains: 100%|██████████| 48000/48000 [02:02<00:00, 391.08draws/s]\n",
      "100%|██████████| 8000/8000 [00:53<00:00, 148.57it/s]\n",
      "/accounts/ekarakoy/anaconda3/envs/bayesian_toa_project/lib/python3.7/site-packages/pymc3/stats.py:167: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.stack(logp)\n",
      "/accounts/ekarakoy/anaconda3/envs/bayesian_toa_project/lib/python3.7/site-packages/pymc3/stats.py:218: UserWarning: For one or more samples the posterior variance of the\n",
      "        log predictive densities exceeds 0.4. This could be indication of\n",
      "        WAIC starting to fail see http://arxiv.org/abs/1507.04544 for details\n",
      "        \n",
      "  \"\"\")\n",
      "/accounts/ekarakoy/anaconda3/envs/bayesian_toa_project/lib/python3.7/site-packages/pymc3/stats.py:299: UserWarning: Estimated shape parameter of Pareto distribution is\n",
      "        greater than 0.7 for one or more samples.\n",
      "        You should consider using a more robust model, this is because\n",
      "        importance sampling is less likely to work well if the marginal\n",
      "        posterior and LOO posterior are very different. This is more likely to\n",
      "        happen with a non-robust model and highly influential observations.\n",
      "  happen with a non-robust model and highly influential observations.\"\"\")\n",
      "100%|██████████| 8000/8000 [00:54<00:00, 147.04it/s]\n",
      "2019-03-11 10:40:40.756 | INFO     | __main__:<module>:11 - processing aphi443\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, bias, w, lambda_m, sd_bias, tau]\n",
      "Sampling 4 chains: 100%|██████████| 48000/48000 [02:03<00:00, 389.57draws/s]\n",
      "100%|██████████| 8000/8000 [00:52<00:00, 152.90it/s]\n",
      "100%|██████████| 8000/8000 [00:53<00:00, 148.37it/s]\n",
      "2019-03-11 10:44:34.856 | INFO     | __main__:<module>:11 - processing aphi489\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, bias, w, lambda_m, sd_bias, tau]\n",
      "Sampling 4 chains: 100%|██████████| 48000/48000 [02:04<00:00, 385.39draws/s]\n",
      "100%|██████████| 8000/8000 [00:53<00:00, 150.82it/s]\n",
      "100%|██████████| 8000/8000 [00:54<00:00, 147.19it/s]\n",
      "2019-03-11 10:48:31.426 | INFO     | __main__:<module>:11 - processing aphi510\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, bias, w, lambda_m, sd_bias, tau]\n",
      "Sampling 4 chains: 100%|██████████| 48000/48000 [01:52<00:00, 425.02draws/s]\n",
      "100%|██████████| 8000/8000 [00:49<00:00, 161.70it/s]\n",
      "100%|██████████| 8000/8000 [00:51<00:00, 154.88it/s]\n",
      "2019-03-11 10:52:10.347 | INFO     | __main__:<module>:11 - processing aphi555\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, bias, w, lambda_m, sd_bias, tau]\n",
      "Sampling 4 chains: 100%|██████████| 48000/48000 [01:55<00:00, 414.69draws/s]\n",
      "100%|██████████| 8000/8000 [00:51<00:00, 156.01it/s]\n",
      "100%|██████████| 8000/8000 [00:50<00:00, 158.47it/s]\n",
      "2019-03-11 10:55:52.780 | INFO     | __main__:<module>:11 - processing aphi670\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, bias, w, lambda_m, sd_bias, tau]\n",
      "Sampling 4 chains: 100%|██████████| 48000/48000 [02:00<00:00, 397.27draws/s]\n",
      "100%|██████████| 8000/8000 [00:50<00:00, 159.30it/s]\n",
      "100%|██████████| 8000/8000 [00:50<00:00, 158.55it/s]\n"
     ]
    }
   ],
   "source": [
    "bands = [411, 443, 489, 510, 555, 670]\n",
    "# create band-keyed dictionary to contain models\n",
    "model_dict=dict.fromkeys(bands)\n",
    "\n",
    "# create theano shared variable\n",
    "X_shared = shared(X_s_train_w_int.values)\n",
    "y_shared = shared(y_train['log10_aphy%d' % bands[0]].values)\n",
    "# Fitting aphi411 model:\n",
    "# Instantiate PyMC3 model with bnn likelihood\n",
    "for band in bands:\n",
    "    logger.info(\"processing aphi{band}\", band=band)\n",
    "    X_shared.set_value(X_s_train_w_int.values)\n",
    "    y_shared.set_value(y_train['log10_aphy%d' % band].values)\n",
    "    hshoe_wi_ = PyMCModel(hs_regression, X_shared, y_shared )\n",
    "    hshoe_wi_.model.name = 'hshoe_wi_aphy%d' %band\n",
    "    hshoe_wi_.fit(n_samples=2000, cores=4, chains=4, tune=10000,\n",
    "                nuts_kwargs=dict(target_accept=0.95))\n",
    "    ppc_train_ = hshoe_wi_.predict(likelihood_name='likelihood')\n",
    "    waic_train = hshoe_wi_.get_waic()\n",
    "    loo_train = hshoe_wi_.get_loo()\n",
    "    model_train = deepcopy(hshoe_wi_.model)\n",
    "    trace = deepcopy(hshoe_wi_.trace_)\n",
    "    run_dict = dict(model_train=model_train, trace=trace,\n",
    "                    ppc_train=ppc_train_, loo_train=loo_train, waic_train=waic_train)\n",
    "    X_shared.set_value(X_s_test_w_int.values)\n",
    "    y_shared.set_value(y_test['log10_aphy%d' % band].values)\n",
    "    model_test = deepcopy(hshoe_wi_.model)\n",
    "    ppc_test_ = hshoe_wi_.predict(likelihood_name='likelihood')\n",
    "    waic_test = hshoe_wi_.get_waic()\n",
    "    loo_test = hshoe_wi_.get_loo()\n",
    "    run_dict.update(dict(model_test=model_test, ppc_test=ppc_test_,\n",
    "                         waic_test=waic_test, loo_test=loo_test))\n",
    "    model_dict[band] = run_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../PickleJar/Results/hshoe_wi_model_dict_%s.pkl' %DT.now(), 'wb') as fb:\n",
    "        pickle.dump(model_dict, fb, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bayesian_toa_project] *",
   "language": "python",
   "name": "conda-env-bayesian_toa_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
